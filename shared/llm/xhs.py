"""
å°çº¢ä¹¦æ–‡æ¡ˆç”Ÿæˆå™¨
â€”â€” å°† WordPress æ–‡ç« æˆ–æœ¬åœ° article.json é€šè¿‡ LLM æ”¹å†™ä¸ºå°çº¢ä¹¦ç¬”è®°
"""

from __future__ import annotations

from dataclasses import dataclass, field
from typing import List, Optional

from shared.llm.client import LLMClient, extract_json_block
from shared.utils.exceptions import ContentGenError, LLMResponseError
from shared.utils.logger import get_logger
from shared.wp.client import WPPost

logger = get_logger("xhs-content")


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ æ•°æ®æ¨¡å‹ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

@dataclass
class XHSContent:
    """å°çº¢ä¹¦ç¬”è®°å†…å®¹"""
    title: str                                           # â‰¤20å­—ï¼Œå¸¦ emoji
    body: str                                            # æ­£æ–‡ï¼Œæ®µè½åˆ†æ˜ï¼Œå¸¦ emoji
    hashtags: List[str] = field(default_factory=list)    # è¯é¢˜æ ‡ç­¾
    image_urls: List[str] = field(default_factory=list)  # é…å›¾ URL æˆ–æœ¬åœ°è·¯å¾„

    # å°çº¢ä¹¦æ­£æ–‡å­—æ•°ä¸Šé™
    XHS_MAX_BODY_LENGTH = 1000

    def full_text(self) -> str:
        """æ‹¼è£…å®Œæ•´å‘å¸ƒæ–‡æœ¬ï¼ˆæ­£æ–‡ + è¯é¢˜æ ‡ç­¾ï¼‰ï¼Œç¡®ä¿ä¸è¶…è¿‡å°çº¢ä¹¦å­—æ•°é™åˆ¶"""
        tags_str = " ".join(f"#{t}" for t in self.hashtags)
        if not tags_str:
            return self.body[:self.XHS_MAX_BODY_LENGTH]
        full = f"{self.body}\n\n{tags_str}"
        if len(full) <= self.XHS_MAX_BODY_LENGTH:
            return full
        # è¶…é•¿æ—¶æˆªæ–­æ­£æ–‡éƒ¨åˆ†ï¼Œä¿ç•™è¯é¢˜æ ‡ç­¾
        max_body = self.XHS_MAX_BODY_LENGTH - len(tags_str) - 5
        return f"{self.body[:max_body]}...\n\n{tags_str}"

    def summary(self) -> str:
        return f"[{self.title}] {len(self.body)}å­— {len(self.hashtags)}æ ‡ç­¾ {len(self.image_urls)}å›¾"

    def to_dict(self) -> dict:
        return {
            "title": self.title,
            "body": self.body,
            "hashtags": self.hashtags,
            "full_text": self.full_text(),
            "image_urls": self.image_urls,
        }

    @classmethod
    def from_dict(cls, data: dict) -> "XHSContent":
        return cls(
            title=data["title"],
            body=data["body"],
            hashtags=data.get("hashtags", []),
            image_urls=data.get("image_urls", []),
        )


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Prompt â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

_XHS_SYSTEM_PROMPT = """ä½ æ˜¯ä¸€ä½å…¨ç½‘ç²‰ä¸ 50w+ çš„å°çº¢ä¹¦å¤´éƒ¨åšä¸»ï¼Œç²¾é€šçˆ†æ¬¾ç¬”è®°çš„å†™ä½œæŠ€å·§ã€‚

## æ ‡é¢˜å…¬å¼ï¼ˆä»»é€‰ä¸€ç§ï¼‰

1. æ•°å­—æ¸…å•å¼ï¼šã€ŒX ä¸ªâ€¦è®©ä½ â€¦ã€ã€Œè¿™ X æ‹›â€¦æˆ‘åæ‚”æ²¡æ—©çŸ¥é“ã€
2. åå·®/é¢ è¦†å¼ï¼šã€Œåˆ«å†â€¦äº†ï¼è¯•è¯•è¿™ä¸ªæ–¹æ³•ã€ã€ŒåŸæ¥â€¦è¿™ä¹ˆç®€å•ã€
3. ç—›ç‚¹å…±é¸£å¼ï¼šã€Œâ€¦çš„äººä¸€å®šè¦çœ‹ã€ã€Œä¸ºä»€ä¹ˆä½ çš„â€¦æ€»æ˜¯ä¸è¡Œï¼Ÿã€
4. å¥½å¥‡é©±åŠ¨å¼ï¼šã€Œæˆ‘é è¿™æ‹›â€¦æ•ˆæœæƒŠäººã€ã€Œç»ˆäºæ‰¾åˆ°â€¦çš„æ­£ç¡®æ‰“å¼€æ–¹å¼ã€

### æ ‡é¢˜è§„åˆ™
- **ä¸è¶…è¿‡ 20 ä¸ªå­—**ï¼ˆç¡¬æ€§é™åˆ¶ï¼‰
- å¸¦ 1-2 ä¸ª emojiï¼ˆæ”¾æ ‡é¢˜å‰é¢æˆ–ç»“å°¾ï¼Œä¸è¦å¤¹åœ¨æ–‡å­—ä¸­é—´ï¼‰
- ç¦æ­¢ä½¿ç”¨å¼•å·ã€ä¹¦åå·
- ç”¨å£è¯­åŒ–è¡¨è¾¾ï¼Œä¸è¦åƒæ–°é—»æ ‡é¢˜

## æ­£æ–‡ç»“æ„

### å¼€å¤´ï¼ˆHookï¼‰â€” å‰ 2 è¡Œå†³å®šç”Ÿæ­»
- ç”¨ä¸€å¥è¯åˆ¶é€ ã€Œå…±é¸£æ„Ÿã€æˆ–ã€Œå¥½å¥‡å¿ƒã€
- ç¤ºä¾‹å¥å¼ï¼šã€Œå§å¦¹ä»¬ï¼â€¦çš„æ—¶å€™æ˜¯ä¸æ˜¯ä¹Ÿâ€¦ã€ã€Œè¯´çœŸçš„ï¼Œç”¨äº†â€¦ä¹‹åæˆ‘æ•´ä¸ªäººéƒ½ä¸ä¸€æ ·äº†ã€ã€Œæäº†Xå¹´â€¦ç»ˆäºæ•´æ˜ç™½äº†ã€

### ä¸­é—´ï¼ˆå¹²è´§ä¸»ä½“ï¼‰
- **å¿…é¡»ä½¿ç”¨åˆ†ç‚¹/åºå·ç»“æ„**ï¼šç”¨ â‘ â‘¡â‘¢ æˆ– 1ï¸âƒ£2ï¸âƒ£3ï¸âƒ£ åˆ—å‡ºè¦ç‚¹ï¼ˆå°çº¢ä¹¦ç”¨æˆ·æœ€çˆ±æ”¶è—æ¸…å•å‹å†…å®¹ï¼‰
- æ¯ä¸ªè¦ç‚¹ 1-2 å¥è¯ï¼Œè¯´äººè¯ï¼Œä¸è¦ç”¨ä¹¦é¢è¯­
- ç©¿æ’çœŸå®åœºæ™¯/ä½¿ç”¨ä½“éªŒæè¿°ï¼Œå¢åŠ ä»£å…¥æ„Ÿ
- å¦‚æœ‰æ•°æ®æˆ–æ¡ˆä¾‹ï¼Œç”¨ã€Œä¸¾ä¸ªä¾‹å­ã€ã€Œå°±æ‹¿â€¦æ¥è¯´ã€ç­‰å£è¯­åŒ–å¼•å…¥
- æ¯æ®µæœ«å°¾å¯åŠ  emoji ç‚¹ç¼€ï¼ˆğŸ”¥ğŸ’¡âœ…ğŸ¯ğŸ“Œï¼‰ï¼Œæ¯æ®µæœ€å¤š 1-2 ä¸ª

### ç»“å°¾ï¼ˆäº’åŠ¨å¼•å¯¼ï¼‰
- ç”¨ä¸€å¥è¯æ€»ç»“æ ¸å¿ƒä»·å€¼
- è‡ªç„¶å¼•å¯¼äº’åŠ¨ï¼ˆäºŒé€‰ä¸€å¼æé—®æ•ˆæœæœ€å¥½ï¼‰
- ç¤ºä¾‹ï¼šã€Œä½ ä»¬è§‰å¾—â€¦è¿˜æ˜¯â€¦æ›´å¥½ç”¨ï¼Ÿè¯„è®ºåŒºèŠèŠï½ã€ã€Œè§‰å¾—æœ‰ç”¨å°±æ”¶è—èµ·æ¥ğŸ’« ä¸‹æ¬¡ç”¨å¾—ä¸Šï¼ã€

### å­—æ•°
- æ­£æ–‡ä¸¥æ ¼æ§åˆ¶åœ¨ **400-800 å­—**ï¼ˆå°çº¢ä¹¦é™åˆ¶ 1000 å­—ï¼Œéœ€é¢„ç•™è¯é¢˜æ ‡ç­¾ç©ºé—´ï¼‰

## è¯é¢˜æ ‡ç­¾
- ç»™å‡º **5-8 ä¸ª**ç›¸å…³è¯é¢˜æ ‡ç­¾
- åªè¾“å‡ºæ ‡ç­¾æ–‡å­—ï¼Œä¸å¸¦ # å·
- å‰ 2 ä¸ªä¸ºçƒ­é—¨å¤§è¯é¢˜ï¼ˆå¦‚ã€ŒèŒåœºå¹²è´§ã€ã€Œæ•ˆç‡å·¥å…·ã€ï¼‰ï¼Œåé¢ä¸ºé•¿å°¾ç²¾å‡†è¯é¢˜
- æœ€å 1 ä¸ªå¯æ”¾å“ç‰Œ/å·¥å…·åç§°ç›¸å…³è¯é¢˜

## è¯­è¨€é£æ ¼
- åƒè·Ÿå¥½æœ‹å‹èŠå¤©ï¼Œç”¨ã€Œæˆ‘ã€ã€Œä½ ã€ã€Œå’±ã€ã€Œå§å¦¹ã€
- å¯ä»¥ç”¨ã€Œï¼ã€è¡¨è¾¾æƒ…ç»ªï¼Œä½†ä¸è¦æ¯å¥éƒ½ç”¨
- ç¦æ­¢ä½¿ç”¨ï¼šã€Œèµ‹èƒ½ã€ã€Œé—­ç¯ã€ã€ŒæŠ“æ‰‹ã€ã€ŒåŠ©åŠ›ã€ã€Œä¸è¨€è€Œå–»ã€ç­‰å®˜æ–¹è¯æ±‡
- ç¦æ­¢ä½¿ç”¨ï¼šã€Œéšç€â€¦çš„å‘å±•ã€ã€Œåœ¨â€¦èƒŒæ™¯ä¸‹ã€ã€Œç»¼ä¸Šæ‰€è¿°ã€ç­‰å­¦æœ¯å¼€å¤´
- å…è®¸å¶å°”ç”¨ç½‘ç»œçƒ­æ¢—ï¼Œä½†ä¸è¦ç¡¬å‡¹

## é‡è¦
- ä¸è¦è™šæ„ä»»ä½•äº‹å®ï¼Œå®Œå…¨åŸºäºåŸæ–‡ä¿¡æ¯æ”¹å†™
- ä¸è¦è¾“å‡ºä»»ä½•è§£é‡Šè¯´æ˜ï¼Œåªè¾“å‡º JSON

## è¾“å‡ºæ ¼å¼

ä¸¥æ ¼è¾“å‡ºä»¥ä¸‹ JSONï¼Œä¸è¦åŒ…è£¹åœ¨ markdown ä»£ç å—ä¸­ï¼š
{"title": "æ ‡é¢˜æ–‡å­—", "body": "æ­£æ–‡å†…å®¹", "hashtags": ["æ ‡ç­¾1", "æ ‡ç­¾2"]}"""


_COMMENT_SYSTEM_PROMPT = """ä½ æ˜¯ä¸€ä½å°çº¢ä¹¦èµ„æ·±ç”¨æˆ·ï¼Œæ“…é•¿åœ¨çƒ­é—¨ç¬”è®°ä¸‹ç•™ä¸‹æœ‰ä»·å€¼çš„è¯„è®ºï¼Œå¸®åŠ©è‡ªå·±çš„ç¬”è®°è·å¾—æ›å…‰ã€‚

## è¯„è®ºè§„åˆ™

### åŸºæœ¬è¦æ±‚
- è¯„è®ºå¿…é¡»ä¸çƒ­é—¨ç¬”è®°å†…å®¹ç›¸å…³ï¼Œæä¾›çœŸæ­£æœ‰ä»·å€¼çš„è§è§£æˆ–è¡¥å……
- è¯­æ°”è‡ªç„¶äº²åˆ‡ï¼Œåƒæ™®é€šç”¨æˆ·åœ¨äº¤æµï¼Œç»å¯¹ä¸èƒ½æœ‰å¹¿å‘Šå«Œç–‘
- è¯„è®ºé•¿åº¦ 30-100 å­—ï¼Œä¸å®œè¿‡é•¿ä¹Ÿä¸èƒ½è¿‡çŸ­
- å¯ä»¥é€‚å½“ä½¿ç”¨ 1-2 ä¸ª emojiï¼Œä½†ä¸è¦å †ç Œ

### å¼•æµç­–ç•¥
- åœ¨è¯„è®ºä¸­è‡ªç„¶åœ°æåˆ°ä½ ä¹Ÿç ”ç©¶/å®è·µè¿‡ç›¸å…³è¯é¢˜
- å¯ä»¥åˆ†äº«ä¸€ä¸ªè‡ªå·±ç›¸å…³çš„å°ç»éªŒæˆ–è¡¥å……è§‚ç‚¹
- å¼•å‘å¥½å¥‡å¿ƒï¼Œè®©äººæƒ³çœ‹ä½ çš„ä¸»é¡µäº†è§£æ›´å¤š
- ç»å¯¹ä¸è¦ç›´æ¥è¯´"çœ‹æˆ‘çš„ç¬”è®°"æˆ–æ”¾é“¾æ¥
- ä¸è¦ç›´æ¥æåŠè‡ªå·±å‘äº†ç›¸å…³ç¬”è®°

### é£æ ¼è¯´æ˜
- professionalï¼ˆä¸“ä¸šï¼‰ï¼šä»¥ä¸“ä¸šè§†è§’è¡¥å……è§è§£ï¼Œä½“ç°ä¸“ä¸šåº¦
- casualï¼ˆéšæ„ï¼‰ï¼šåƒæœ‹å‹èŠå¤©ä¸€æ ·è½»æ¾å›å¤ï¼Œæœ‰å…±é¸£æ„Ÿ
- enthusiasticï¼ˆçƒ­æƒ…ï¼‰ï¼šè¡¨è¾¾å¼ºçƒˆè®¤åŒå¹¶è¡¥å……è‡ªå·±çš„å®è·µç»éªŒ

### ç»å¯¹ç¦æ­¢
- å¹¿å‘Šè¯ã€è¥é”€è¯æœ¯
- è´¬ä½åŸç¬”è®°å†…å®¹
- æ— å…³å†…å®¹æˆ–çº¯è¡¨æƒ…
- ç›´æ¥å¼•å¯¼åˆ°è‡ªå·±çš„ç¬”è®°/ä¸»é¡µ
- "äº’å…³"ã€"å›å…³"ç­‰ä½è´¨é‡äº’åŠ¨

## è¾“å‡º
åªè¾“å‡ºä¸€æ¡è¯„è®ºæ–‡æœ¬ï¼Œä¸è¦åŠ ä»»ä½•è§£é‡Šã€å¼•å·æˆ–æ ¼å¼æ ‡è®°ã€‚"""


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ç”Ÿæˆå™¨ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

class XHSContentGenerator:
    """è°ƒç”¨ LLM å°† WP æ–‡ç« æˆ–æœ¬åœ°æ–‡ç« è½¬åŒ–ä¸ºå°çº¢ä¹¦æ–‡æ¡ˆ"""

    def __init__(self, llm: LLMClient) -> None:
        self.llm = llm

    def generate_from_post(self, post: WPPost) -> XHSContent:
        """è¾“å…¥ WordPress æ–‡ç« ï¼Œè¾“å‡ºå°çº¢ä¹¦ç¬”è®°å¯¹è±¡"""
        user_msg = self._build_user_message_from_post(post)
        logger.info("ç”Ÿæˆå°çº¢ä¹¦æ–‡æ¡ˆï¼Œæ–‡ç« : [%s] %s", post.id, post.title)

        raw = self._call_llm(user_msg)
        content = self._parse_response(raw, fallback_title=post.title, image_urls=post.all_image_urls[:9])
        logger.info("æ–‡æ¡ˆç”Ÿæˆå®Œæˆ: %s", content.summary())
        return content

    def generate_from_article(self, article: dict, image_paths: Optional[list] = None) -> XHSContent:
        """ä»æœ¬åœ° article.json ç”Ÿæˆå°çº¢ä¹¦æ–‡æ¡ˆ"""
        user_msg = self._build_user_message_from_article(article)
        logger.info("ç”Ÿæˆå°çº¢ä¹¦æ–‡æ¡ˆï¼ˆæœ¬åœ°ç´ æï¼‰ï¼Œæ ‡é¢˜: %s", article.get("title", ""))

        raw = self._call_llm(user_msg)
        images = (image_paths or [])[:9]
        content = self._parse_response(raw, fallback_title=article.get("title", "")[:20], image_urls=images)
        logger.info("æ–‡æ¡ˆç”Ÿæˆå®Œæˆï¼ˆæœ¬åœ°ç´ æï¼‰: %s", content.summary())
        return content

    def _call_llm(self, user_msg: str) -> str:
        """è°ƒç”¨ LLM"""
        raw = self.llm.chat(
            system_prompt=_XHS_SYSTEM_PROMPT,
            user_prompt=user_msg,
            temperature=0.7,
        )
        if not raw:
            raise ContentGenError("LLM è°ƒç”¨å¤±è´¥ï¼Œæœªè¿”å›å†…å®¹")
        return raw

    @staticmethod
    def _parse_response(raw: str, fallback_title: str, image_urls: list) -> XHSContent:
        """è§£æ LLM è¿”å›çš„ JSON"""
        data = extract_json_block(raw)
        if data is None:
            raise LLMResponseError(f"æ— æ³•ä» LLM è¾“å‡ºä¸­æå– JSON: {raw[:200]}")

        title = data.get("title", "").strip() or fallback_title
        body = data.get("body", "").strip()
        if not body:
            raise LLMResponseError("LLM è¿”å›çš„æ­£æ–‡ä¸ºç©º")

        hashtags = data.get("hashtags", [])
        if not isinstance(hashtags, list):
            hashtags = []
        hashtags = [str(t).strip() for t in hashtags if t]

        return XHSContent(
            title=title,
            body=body,
            hashtags=hashtags,
            image_urls=image_urls,
        )

    @staticmethod
    def _build_user_message_from_post(post: WPPost) -> str:
        parts = [f"æ–‡ç« æ ‡é¢˜ï¼š{post.title}"]
        if post.excerpt:
            parts.append(f"æ–‡ç« æ‘˜è¦ï¼š{post.excerpt}")
        content_text = post.content[:3000]
        if len(post.content) > 3000:
            content_text += "\n...(æ­£æ–‡å·²æˆªæ–­)"
        parts.append(f"æ–‡ç« æ­£æ–‡ï¼š\n{content_text}")
        if post.tags:
            parts.append(f"æ–‡ç« æ ‡ç­¾ï¼š{', '.join(post.tags)}")
        if post.categories:
            parts.append(f"æ–‡ç« åˆ†ç±»ï¼š{', '.join(post.categories)}")
        return "\n\n".join(parts)

    # â”€â”€ è¯„è®ºç”Ÿæˆ â”€â”€

    def generate_comment(
        self,
        note_title: str,
        note_body: str,
        my_note_title: str,
        my_note_summary: str,
        style: str = "professional",
    ) -> str:
        """
        åŸºäºçƒ­é—¨ç¬”è®°å†…å®¹å’Œè‡ªå·±çš„ç¬”è®°ä¿¡æ¯ï¼Œç”Ÿæˆä¸€æ¡è‡ªç„¶ã€æœ‰ä»·å€¼çš„å¼•æµè¯„è®ºã€‚

        Args:
            note_title: çƒ­é—¨ç¬”è®°æ ‡é¢˜
            note_body: çƒ­é—¨ç¬”è®°æ­£æ–‡ç‰‡æ®µ
            my_note_title: è‡ªå·±å‘å¸ƒçš„ç¬”è®°æ ‡é¢˜
            my_note_summary: è‡ªå·±ç¬”è®°çš„ç®€çŸ­æ‘˜è¦/æ ¸å¿ƒå–ç‚¹
            style: è¯„è®ºé£æ ¼ï¼ˆprofessional / casual / enthusiasticï¼‰
        """
        logger.info("ç”Ÿæˆå¼•æµè¯„è®ºï¼Œç›®æ ‡ç¬”è®°: %s", note_title[:30])
        user_msg = (
            f"## æˆ‘è¦è¯„è®ºçš„çƒ­é—¨ç¬”è®°\n"
            f"æ ‡é¢˜ï¼š{note_title}\n"
            f"æ­£æ–‡ç‰‡æ®µï¼š{note_body[:500]}\n\n"
            f"## æˆ‘è‡ªå·±çš„ç¬”è®°ä¿¡æ¯\n"
            f"æ ‡é¢˜ï¼š{my_note_title}\n"
            f"æ ¸å¿ƒå†…å®¹ï¼š{my_note_summary}\n\n"
            f"## è¯„è®ºé£æ ¼è¦æ±‚\n"
            f"é£æ ¼ï¼š{style}"
        )
        raw = self.llm.chat(
            system_prompt=_COMMENT_SYSTEM_PROMPT,
            user_prompt=user_msg,
            temperature=0.8,
        )
        if not raw:
            raise ContentGenError("LLM è¯„è®ºç”Ÿæˆå¤±è´¥")

        # æå–çº¯æ–‡æœ¬è¯„è®ºï¼ˆå»é™¤å¼•å·å’Œå¤šä½™ç©ºç™½ï¼‰
        comment = raw.strip().strip('"').strip("'").strip()
        # å¦‚æœ LLM è¿”å›äº† JSONï¼Œæå– comment å­—æ®µ
        parsed = extract_json_block(raw)
        if parsed and "comment" in parsed:
            comment = parsed["comment"].strip()

        logger.info("è¯„è®ºç”Ÿæˆå®Œæˆ (%då­—): %s", len(comment), comment[:50])
        return comment

    def generate_comments_batch(
        self,
        notes: list,
        my_note_title: str,
        my_note_summary: str,
        style: str = "professional",
    ) -> list:
        """
        ä¸ºå¤šæ¡çƒ­é—¨ç¬”è®°æ‰¹é‡ç”Ÿæˆè¯„è®ºã€‚

        Args:
            notes: [{"title": ..., "body": ...}, ...]
            my_note_title: è‡ªå·±çš„ç¬”è®°æ ‡é¢˜
            my_note_summary: è‡ªå·±ç¬”è®°çš„æ‘˜è¦
            style: è¯„è®ºé£æ ¼

        Returns:
            [{"note_title": ..., "comment": ...}, ...]
        """
        results = []
        for note in notes:
            try:
                comment = self.generate_comment(
                    note_title=note.get("title", ""),
                    note_body=note.get("body", ""),
                    my_note_title=my_note_title,
                    my_note_summary=my_note_summary,
                    style=style,
                )
                results.append({
                    "note_title": note.get("title", ""),
                    "comment": comment,
                })
            except Exception as e:
                logger.warning("è¯„è®ºç”Ÿæˆå¤±è´¥ï¼Œè·³è¿‡: %s - %s", note.get("title", "")[:20], e)
        return results

    @staticmethod
    def _build_user_message_from_article(article: dict) -> str:
        parts = [f"æ–‡ç« æ ‡é¢˜ï¼š{article.get('title', '')}"]
        excerpt = article.get("excerpt", "")
        if excerpt:
            parts.append(f"æ–‡ç« æ‘˜è¦ï¼š{excerpt}")
        sections = article.get("sections", [])
        body_parts = []
        for sec in sections:
            heading = sec.get("title", sec.get("heading", ""))
            paragraphs = sec.get("paragraphs", [])
            if heading:
                body_parts.append(heading)
            body_parts.extend(paragraphs)
        body_text = "\n".join(body_parts)
        if len(body_text) > 3000:
            body_text = body_text[:3000] + "\n...(æ­£æ–‡å·²æˆªæ–­)"
        parts.append(f"æ–‡ç« æ­£æ–‡ï¼š\n{body_text}")
        takeaways = article.get("key_takeaways", [])
        if takeaways:
            parts.append(f"å…³é”®è¦ç‚¹ï¼š{', '.join(takeaways)}")
        tags = article.get("tags", [])
        if tags:
            parts.append(f"æ–‡ç« æ ‡ç­¾ï¼š{', '.join(tags)}")
        return "\n\n".join(parts)
